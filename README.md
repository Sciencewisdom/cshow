# 我的nnU-Net v2学习与实践心得

大家好！根据老师的要求，今天我想和大家分享一下我在本课程学习过程中的一些心得，特别是我在尝试使用和优化 nnU-Net v2 框架进行医学图像分割时的一些经验和体会。

---

## 1. 初识 nnU-Net v2 

* **什么是 nnU-Net v2？**
    * 它不是一个全新的网络结构，而是一个“开箱即用”的深度学习框架，核心理念是“No New Net”。
    * 它能够根据特定数据集的属性，**自动化地**配置和优化整个医学图像分割流程，包括预处理、网络架构选择、训练策略和后处理。
* **为什么选择它？**
    * **自动化程度高**：大大减少了手动设计和调试模型所需的时间和专业知识。
    * **性能强大**：在多种医学图像分割竞赛和任务中都取得了顶尖的成绩，为我们提供了一个非常高的起点。
    * **适应性强**：能够处理不同模态、不同维度（2D/3D）的医学影像数据。
* **核心工作流程简介**：
    1.  **数据集指纹 (Dataset Fingerprint)**：分析数据集的关键特征。
    2.  **自动配置 (Automatic Configuration)**：基于指纹和预设规则，确定预处理、网络架构（如 `2d`, `3d_fullres`, `3d_lowres`）、训练参数等。
    3.  **训练与推理**：使用标准化命令进行模型训练和预测。

---

## 2. 我的 nnU-Net v2 实践之旅

### 2.1 基础环境与流程搭建

* **环境准备**：按照官方文档，使用 Conda 创建独立环境，安装适配CUDA版本的PyTorch，然后从GitHub克隆并安装nnU-Net v2。
    * `conda create -n nnunet python=3.x`
    * `pip install torch torchvision torchaudio --index-url ...`
    * `git clone https://github.com/MIC-DKFZ/nnUNet.git && cd nnUNet && pip install -e .`
* **环境变量配置**：设置 `nnUNet_raw`, `nnUNet_preprocessed`, `nnUNet_results` 三个核心路径。
    * `nnUNetv2_install` (推荐) 或手动写入 `.bashrc`/`.zshrc`。
* **数据准备**：
    * 严格遵循 nnU-Net 的数据格式要求（NIfTI格式，特定的文件夹结构和命名规则）。
    * 关键在于正确创建 `dataset.json` 文件，它描述了数据集的元信息。
    * 使用 `nnUNetv2_verify_dataset_integrity` 检查数据完整性。
* **核心命令实践**：
    * `nnUNetv2_plan_and_preprocess -d DATASET_ID`: 进行实验规划和数据预处理。
    * `nnUNetv2_train DATASET_ID CONFIGURATION FOLD`: 训练模型，例如 `nnUNetv2_train 1 3d_fullres 0`。
    * `nnUNetv2_predict -i INPUT_FOLDER -o OUTPUT_FOLDER -d DATASET_ID -c CONFIGURATION`: 进行推理预测。

### 2.2 参数调优与优化探索（我的“试错”与学习）

在竞赛中，我基于 nnU-Net v2 的默认配置 (`3d_fullres` 作为基线) 进行了一系列参数调优尝试：

* **更深的网络架构 (ResEncL)**：
    * **尝试**：使用 `nnUNetPlannerResEncL`。
    * **发现**：训练时间显著增加，但对我的肺癌数据集，Dice系数提升非常微小 (<0.01)。
    * **感悟**：并非越深越好，标准U-Net的深度对当前任务可能已足够。
* **前景过采样比例**：
    * **尝试**：对比默认的 `0.33` 和更高的 `0.7`。
    * **发现**：`0.7` 的效果反而略差。
    * **感悟**：过高的前景采样可能让模型忽视背景和边界的学习，默认值在平衡学习上表现更好。
* **初始学习率**：
    * **尝试**：测试了 `0.1`, `0.05`，与默认的 `0.01` 对比。
    * **发现**：`0.01` 非常稳定有效，更高的学习率导致训练不稳定或效果差。
    * **感悟**：nnU-Net的默认参数确实经过了大量验证，具有普适性。
* **学习率调整策略**：
    * **尝试**：实现了一个类似 `ReduceLROnPlateau` 的自适应策略，与默认的 `Polynomial Decay` 对比。
    * **发现**：自适应策略效果不如默认的平滑多项式衰减。
    * **感悟**：医学图像验证集性能波动可能较大，导致自适应策略过早降低学习率。
* **替代训练器 (nnUNetTrainerAdanCosAnneal)**：
    * **尝试**：使用 Adan 优化器和 Cosine Annealing 学习率调度。
    * **发现**：平均性能与默认 SGD+PolyLR 差异不大，但部分折数的性能标准差有所增大。
    * **感悟**：默认组合的鲁棒性和竞争力很强。
* **损失函数权重 (进行中)**：
    * **问题**：观察到模型在肿瘤**边缘区域**的分割精度有待提高。
    * **尝试**：调整 Dice Loss 和 Cross-Entropy (CE) Loss 的权重，例如增加 Dice Loss 的比重 (如 Dice 0.7, CE 0.3)，期望更强调区域重叠，同时保留CE对像素级准确性的约束。
    * **期待**：找到更能平衡区域重叠和边缘精度的组合。

### 2.3 定制化后处理

* **动机**：肺癌通常存在多发病灶，nnU-Net 默认的保留最大连通分量 (LCC) 策略不适用。且临床上关注有一定体积的肿瘤。
* **实践**：
    1.  移除了 LCC 策略。
    2.  编写了Python脚本，实现：
        * **概率阈值处理**：Softmax 输出概率 > 0.5 才标记为肿瘤。
        * **连通组件分析与体积滤波**：移除体积小于特定阈值（如40个体素，根据数据集特性和临床意义设定）的小区域，以滤除噪声和临床意义不大的分割结果。

### 2.4 模型集成 

* **策略**：
    1.  训练多种标准配置模型 (2D, 3d_fullres, 3d_lowres, 3d_cascade_fullres)。
    2.  使用 `nnUNetv2_find_best_configuration` 自动评估和推荐集成方案。
    3.  尝试自定义加权平均，根据各模型在验证集上的表现赋予不同权重。

---

## 3. 主要收获与挑战 

* **主要收获**：
    * nnU-Net v2 确实是一个非常强大的自动化框架，为我们提供了坚实的起点。
    * 其**默认参数和配置往往非常鲁棒且高效**，盲目调整未必能带来提升，理解其设计哲学很重要。
    * 针对具体任务的**定制化调整**（尤其是损失函数侧重、后处理逻辑）是提升性能的关键。例如，我的后处理脚本对去除假阳性有明显帮助。
    * **系统性实验和记录**非常重要，便于分析和迭代。
* **遇到的挑战**：
    * **边缘分割精度**：是目前优化的重点，正通过调整损失函数权重等方法尝试解决。
    * **参数调优的平衡**：如何在特定数据集上取得好效果，同时避免过拟合，是一个持续的挑战。
    * **计算资源和时间**：nnU-Net 的训练，特别是3D模型和多折交叉验证，对GPU和时间有一定要求。

---

## 4. 总结 

总的来说，学习和使用 nnU-Net v2 的过程，是一个从理解其自动化优势，到通过实践和针对性实验不断深化认识、解决具体问题的过程。它不仅是一个工具，更提供了一套系统性的医学图像分割方法论。
